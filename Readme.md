# Proyecto Desarrollo de Soluciones

Proyecto de ciencia de datos enfocado en el desarrollo de soluciones analÃ­ticas utilizando tÃ©cnicas de machine learning y anÃ¡lisis exploratorio de datos.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un pipeline de ciencia de datos completo, desde el anÃ¡lisis exploratorio hasta el desarrollo de modelos predictivos, utilizando herramientas modernas para el versionado de datos y reproducibilidad de experimentos.

## Breve explicaciÃ³n del cÃ³digo predictivo

Carga de modelos entrenados por tienda.
El script busca archivos en model/trained/store_models/ con el patrÃ³n model_<partner>_<store>.pkl y los carga con joblib. Cada archivo representa un modelo ya entrenado para una tienda particular (identificada por <partner_code>_<store_code>).

DefiniciÃ³n del horizonte de predicciÃ³n.
A partir de los argumentos de lÃ­nea de comandos, se define la fecha de inicio (por defecto, maÃ±ana) y el nÃºmero de dÃ­as a predecir (por defecto, 7). TambiÃ©n se puede limitar a una tienda especÃ­fica con --store PARTNER_STORE.

Plantilla de datos futuros.
Usando los datos histÃ³ricos (cargados desde la ruta configurada en config.app_config.train_data_file), se genera una plantilla para las fechas futuras de cada tienda.

Se toma una ventana reciente (p. ej., Ãºltimos 60 dÃ­as) como referencia.

Se extraen estadÃ­sticas por dÃ­a de la semana para el target (tÃ­picamente billings), y se generan valores simulados (media por dÃ­a Â± ruido controlado) para alimentar el pipeline de features.

Se actualizan las variables temporales: aÃ±o, mes, dÃ­a, trimestre, semana del aÃ±o, dÃ­a de la semana, banderas de inicio/fin de mes, etc.

Opcionalmente se simulan otras columnas (p. ej., promocion_activa, precio_promedio, etc.) con pequeÃ±as variaciones.

Preprocesamiento + predicciÃ³n.
La plantilla se transforma con lifemiles_improved_preprocessing_pipe y, sobre las columnas disponibles definidas en get_improved_feature_columns(), se ejecuta el mÃ©todo .predict() del modelo correspondiente a la tienda. El resultado es un DataFrame con: fecha, partner, tienda y predicted_monto.

Salida y resumen.

Se imprime un resumen en consola por tienda (rango de fechas y totales).

Se consolidan todas las predicciones y se guardan en un CSV (por defecto, predicciones_futuras.csv, modificable con --output).

Se reporta el total de predicciones y tiendas procesadas.

## ğŸ—ï¸ Estructura del Proyecto

```
Proyecto_desarrollo_de_soluciones/
â”œâ”€â”€ .dvc/                    # ConfiguraciÃ³n de Data Version Control
â”œâ”€â”€ EDA/                     # AnÃ¡lisis Exploratorio de Datos
â”‚   â””â”€â”€ *.ipynb             # Notebooks de anÃ¡lisis
â”œâ”€â”€ .dvcignore              # Archivos ignorados por DVC
â”œâ”€â”€ .gitignore              # Archivos ignorados por Git
â”œâ”€â”€ data.dvc                # Referencias de datos versionados
â””â”€â”€ README.md               # Este archivo
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python** - Lenguaje principal de desarrollo
- **Jupyter Notebook** - Desarrollo interactivo y anÃ¡lisis
- **DVC (Data Version Control)** - Versionado de datos y experimentos
- **Git** - Control de versiones del cÃ³digo

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.8+
- Git
- DVC

### ConfiguraciÃ³n del Entorno

```bash
# Clonar el repositorio
git clone https://github.com/estebann-2/Proyecto_desarrollo_de_soluciones.git
cd Proyecto_desarrollo_de_soluciones

# Instalar DVC
pip install dvc

# Configurar DVC y descargar datos
dvc pull

# Instalar dependencias (si existe requirements.txt)
pip install -r requirements.txt
```

## ğŸ“Š Uso

1. **AnÃ¡lisis Exploratorio**: Navegar a la carpeta `EDA/` y ejecutar los notebooks
2. **Datos**: Los datos estÃ¡n versionados con DVC - usar `dvc pull` para obtener la Ãºltima versiÃ³n
3. **Experimentos**: Seguir la estructura de notebooks para reproducir anÃ¡lisis

## ğŸ“ Componentes Principales

### EDA (Exploratory Data Analysis)

Contiene notebooks de Jupyter con anÃ¡lisis exploratorio detallado de los datos, incluyendo:

- Limpieza y preprocesamiento de datos
- Visualizaciones y estadÃ­sticas descriptivas
- IdentificaciÃ³n de patrones y insights

### Control de Versiones de Datos

- **DVC** gestiona las versiones de los datasets
- **Git** controla el cÃ³digo y metadatos
- Reproducibilidad garantizada de experimentos

## ğŸ‘¥ Contribuidores

- **[estebann-2](https://github.com/estebann-2)** - Esteban Caicedo
- **[crdadiaz855-web](https://github.com/crdadiaz855-web)**
- **[jucagu](https://github.com/Jucagu)** - Juan Camilo Gutierrez Diaz

## ğŸ”„ Workflow de Desarrollo

1. AnÃ¡lisis exploratorio en notebooks
2. Versionado de datos con DVC
3. Control de versiones de cÃ³digo con Git
4. DocumentaciÃ³n de resultados y metodologÃ­a

## ğŸ“ˆ PrÃ³ximos Pasos

- [x] Agregar documentaciÃ³n detallada de metodologÃ­a
- [x] Implementar pipeline de ML automatizado
- [x] Agregar tests unitarios para funciones de procesamiento
- [x] Crear visualizaciones interactivas

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ“ Contacto

Para preguntas o colaboraciones, contactar a los contribuidores del proyecto a travÃ©s de GitHub.

---

**Desarrollado con ğŸ’» y â˜• por el equipo de Desarrollo de Soluciones**
